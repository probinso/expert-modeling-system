{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, defaultdict, Counter\n",
    "from glob import glob\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel as LDA\n",
    "from gensim.models import AuthorTopicModel as ATM\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pandas import DataFrame, read_csv, concat\n",
    "\n",
    "import pyLDAvis as ldavis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.sparse import coo_matrix as sparse_matrix\n",
    "\n",
    "ldavis.enable_notebook()\n",
    "%matplotlib notebook\n",
    "#%precision 4\n",
    "\n",
    "out = Path('../output/')\n",
    "\n",
    "Candidate = namedtuple('Candidate', ['iterations', 'num_topics'])\n",
    "\n",
    "\n",
    "\n",
    "def get_i_t(filename):\n",
    "    _, content, document_type = filename.split('-')\n",
    "    i, t, _ = content.split('_')\n",
    "    return int(i[1:]), int(t[1:]), document_type.split('.')[0]\n",
    "\n",
    "get_texts = lambda df: df[target].str.split()\n",
    "tobows = lambda df, d: concat([df['Anomaly_ID'], get_texts(df).apply(d.doc2bow)], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "isr2 = 2.0 ** -.5\n",
    "\n",
    "def hellinger(x, y):\n",
    "    return isr2 * np.sqrt(((np.sqrt(x) - np.sqrt(y)) ** 2).sum())\n",
    "\n",
    "\n",
    "\n",
    "report_types = 'ISA', 'PFR', 'DPFR'\n",
    "\n",
    "TEST_SIZE = 0.3\n",
    "min_occurances = 2\n",
    "target = 'GLOMUNSTEM'\n",
    "\n",
    "%matplotlib notebook\n",
    "%precision 4\n",
    "\n",
    "BASEDIR = Path('../data')\n",
    "OUT = Path('../output/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(BASEDIR / 'processed_authors.csv') as fd:\n",
    "    af = read_csv(fd)\n",
    "af.shape\n",
    "af.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_by_type = {\n",
    "    t: af[af.ReportType == t] \n",
    "    for t in af.ReportType.unique()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_by_type = {\n",
    "    t: read_csv(OUT / f'norm_{t}.csv').dropna()\n",
    "    for t in af.ReportType.unique()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document_type in documents_by_type:\n",
    "    documents_by_type[document_type].Anomaly_ID = \\\n",
    "      'A' + documents_by_type[document_type].Anomaly_ID.apply(str)\n",
    "\n",
    "    \n",
    "    documents_by_type[document_type]['Attributed'] = False\n",
    "    idx = documents_by_type[document_type].Anomaly_ID.isin(\n",
    "        authors_by_type[document_type].Anomaly_ID.unique()\n",
    "    )\n",
    "    documents_by_type[document_type]['Attributed'][idx] = True\n",
    "    \n",
    "    idx = authors_by_type[document_type].Anomaly_ID.isin(\n",
    "        documents_by_type[document_type].Anomaly_ID.unique()\n",
    "    )\n",
    "    authors_by_type[document_type] = authors_by_type[document_type][idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_and_vocab(documents, test_size, min_occurances=min_occurances):\n",
    "    train, test = train_test_split(\n",
    "        documents, test_size=test_size,\n",
    "        stratify=documents['Attributed']\n",
    "    )\n",
    "    train.reset_index(drop=True, inplace=True)\n",
    "    test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    vocab = Dictionary(\n",
    "        train[target].str.split()\n",
    "    )\n",
    "    vocab.filter_extremes(no_below=min_occurances)\n",
    "\n",
    "    return train, test, vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('election_by_type.pkl', 'rb') as fd:\n",
    "    election_by_type = pickle.load(fd)\n",
    "\n",
    "model_by_type, train_documents_by_type, test_documents_by_type, dictionary_by_type = \\\n",
    "  dict(), dict(), dict(), dict()\n",
    "\n",
    "train_author_table_by_type = dict()\n",
    "test_author_table_by_type = dict()\n",
    "\n",
    "def attribution_table(documents, relevent_authors):\n",
    "    store = defaultdict(set)\n",
    "    for idx, anomaly in documents.iterrows():\n",
    "        authors_documents = relevent_authors[\n",
    "            relevent_authors.Anomaly_ID == anomaly.Anomaly_ID\n",
    "        ]\n",
    "\n",
    "        for author in authors_documents.Users_ID:\n",
    "            store[author].add(idx)\n",
    "\n",
    "    return {k: list(v) for k, v in store.items()}\n",
    "\n",
    "\n",
    "for document_type in election_by_type:\n",
    "    c = election_by_type[document_type]\n",
    "\n",
    "    train_documents_by_type[document_type], \\\n",
    "    test_documents_by_type[document_type], \\\n",
    "    dictionary_by_type[document_type] = \\\n",
    "        get_train_test_and_vocab(documents_by_type[document_type], TEST_SIZE)\n",
    "    \n",
    "    train_author_table_by_type[document_type] = attribution_table(\n",
    "        train_documents_by_type[document_type],\n",
    "        authors_by_type[document_type]\n",
    "    )\n",
    "    \n",
    "    test_author_table_by_type[document_type] = attribution_table(\n",
    "        test_documents_by_type[document_type],\n",
    "        authors_by_type[document_type]\n",
    "    )\n",
    "    \n",
    "    print(f'{document_type: <4}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document_type in election_by_type:\n",
    "    c = election_by_type[document_type]\n",
    "\n",
    "    corpus = tobows(\n",
    "        train_documents_by_type[document_type],\n",
    "        dictionary_by_type[document_type]\n",
    "    )[target]\n",
    "\n",
    "    atm = ATM(\n",
    "        corpus=list(corpus),\n",
    "        author2doc=train_author_table_by_type[document_type],\n",
    "        num_topics=c.num_topics,\n",
    "        iterations=c.iterations,\n",
    "    )\n",
    "    model_by_type[document_type] = atm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_topics(model, doc_bow):\n",
    "\n",
    "    gamma_chunk, sstats = model.inference(\n",
    "        chunk=[doc_bow], author2doc=dict(), doc2author=dict(), \n",
    "        rhot=1.00,\n",
    "        collect_sstats=True\n",
    "    )\n",
    "\n",
    "    return gamma_chunk\n",
    "\n",
    "\n",
    "def get_model_author_topic_vectors(model):\n",
    "    author_topic_vectors = np.zeros(\n",
    "        (model.num_authors, model.num_topics)\n",
    "    )\n",
    "\n",
    "    for i, author in enumerate(model.id2author.values()):\n",
    "        idx, scores = zip(*model.get_author_topics(author))\n",
    "        author_topic_vectors[i, idx] = scores\n",
    "\n",
    "    return author_topic_vectors\n",
    "\n",
    "\n",
    "def get_sorted_authors(model, doc_bow, author_topic_vectors, metric=hellinger):\n",
    "    doc_vector = get_document_topics(model, doc_bow)\n",
    "\n",
    "    author_scores = np.argsort(\n",
    "        cdist(doc_vector, author_topic_vectors, metric=metric)\n",
    "    )\n",
    "    if author_scores:\n",
    "        contenders = [\n",
    "            model.id2author[idx]\n",
    "            for idx in author_scores[0]\n",
    "        ]\n",
    "    else:\n",
    "        contenders = []\n",
    "\n",
    "    return contenders\n",
    "\n",
    "\n",
    "def get_all_ranks_and_counts(model, publication_counts, authors, dictionary, documents):\n",
    "    author_topic_vectors = get_model_author_topic_vectors(model)\n",
    "\n",
    "    for idx, row in tobows(documents, dictionary).iterrows():\n",
    "        Anomaly_ID, doc_bow = row['Anomaly_ID'], row[target]\n",
    "\n",
    "        contenders = get_sorted_authors(model, doc_bow, author_topic_vectors)\n",
    "        if not contenders:\n",
    "            continue\n",
    "        \n",
    "        real_authors = [\n",
    "            a\n",
    "            for a in authors\n",
    "            if idx in authors[a]\n",
    "        ]\n",
    "\n",
    "        for a in real_authors:\n",
    "            try:\n",
    "                rank = contenders.index(a)\n",
    "            except ValueError as e:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                publications = publication_counts[a]\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "            yield publications, contenders.index(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_author_table_by_type\n",
    "\n",
    "publication_counts_by_type = dict()\n",
    "for t in train_author_table_by_type:\n",
    "    _authors = train_author_table_by_type[t]\n",
    "    publication_counts_by_type[t] = {a: len(_authors[a]) for a in _authors}\n",
    "    del _authors\n",
    "\n",
    "train = list(get_all_ranks_and_counts(\n",
    "    model_by_type['ISA'],\n",
    "    publication_counts_by_type['ISA'],\n",
    "    train_author_table_by_type['ISA'],\n",
    "    dictionary_by_type['ISA'],\n",
    "    train_documents_by_type['ISA']\n",
    "))\n",
    "\n",
    "test = list(get_all_ranks_and_counts(\n",
    "    model_by_type['ISA'],\n",
    "    publication_counts_by_type['ISA'],\n",
    "    test_author_table_by_type['ISA'],\n",
    "    dictionary_by_type['ISA'],\n",
    "    test_documents_by_type['ISA']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_arc(arc):\n",
    "    _ = plt.figure()\n",
    "    # Load the dataset\n",
    "    data = DataFrame(columns=[\"publications\", \"rank\"], data=arc)\n",
    "    _ = sns.jointplot(x=data['publications'], y=data['rank'], \n",
    "                      kind='hex',\n",
    "                      #xlim=(0, 250), ylim=(0, 300), gridsize=20,\n",
    "                     )\n",
    "\n",
    "plot_arc(train)\n",
    "plot_arc(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
