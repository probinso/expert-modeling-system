{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from glob import glob\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel as LDA\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pandas import DataFrame, read_csv, concat\n",
    "\n",
    "import pyLDAvis as ldavis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ldavis.enable_notebook()\n",
    "%matplotlib notebook\n",
    "%precision 4\n",
    "\n",
    "out = Path('../output/lda')\n",
    "\n",
    "Candidate = namedtuple('Candidate', ['iterations', 'num_topics'])\n",
    "\n",
    "def get_i_t(filename):\n",
    "    _, content, document_type = filename.split('-')\n",
    "    i, t, _ = content.split('_')\n",
    "    return int(i[1:]), int(t[1:]), document_type.split('.')[0]\n",
    "\n",
    "get_texts = lambda df: df[target].str.split()\n",
    "tobows = lambda df, d: get_texts(df).apply(d.doc2bow)\n",
    "\n",
    "report_types = 'ISA', 'PFR', 'DPFR'\n",
    "\n",
    "test_size = .2\n",
    "min_occurances = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_by_type = {\n",
    "    t: read_csv(out / f'norm_{t}.csv').dropna()\n",
    "    for t in report_types\n",
    "}\n",
    "\n",
    "target = 'GLOMUNSTEM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_by_type['ISA'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raise 'think about it'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_by_type, train_by_type, test_by_type = dict(), dict(), dict()\n",
    "for document_type in documents_by_type:\n",
    "    train_by_type[document_type], test_by_type[document_type] = \\\n",
    "      train_test_split(\n",
    "        documents_by_type[document_type], test_size=test_size\n",
    "      )\n",
    "\n",
    "    dictionary_by_type[document_type] = Dictionary(\n",
    "        train_by_type[document_type][target].str.split()\n",
    "    )\n",
    "    dictionary_by_type[document_type].filter_extremes(no_below=min_occurances)\n",
    "\n",
    "with open('dict_train_test.pkl', 'wb') as fd:\n",
    "    pickle.dump([dictionary_by_type, train_by_type, test_by_type], fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('dict_train_test.pkl', 'rb') as fd:\n",
    "    dictionary_by_type, train_by_type, test_by_type = pickle.load(fd)\n",
    "\n",
    "for document_type in train_by_type:\n",
    "    corpus = tobows(train_by_type[document_type], dictionary_by_type[document_type])\n",
    "\n",
    "    for iterations in range(1, 400, 50):\n",
    "        print(document_type, iterations, end=' - ')\n",
    "        for num_topics in range(1, 120, 20):\n",
    "\n",
    "            lda = LDA(corpus=corpus,\n",
    "                        num_topics=num_topics,\n",
    "                        iterations=iterations,\n",
    "                       )\n",
    "            print(num_topics, end=':')\n",
    "\n",
    "            savename = f'wide-i{iterations:03}_t{num_topics:03}_d-{document_type}'\n",
    "            lda.save(str(out / f'{savename}.lda'))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(out / 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict_train_test.pkl', 'rb') as fd:\n",
    "    dictionary_by_type, train_by_type, test_by_type = pickle.load(fd)\n",
    "\n",
    "for filename in glob(str(out / 'wide-*.lda')):\n",
    "    iterations, num_topics, document_type = get_i_t(filename)\n",
    "\n",
    "    # holdout not used intentionally\n",
    "    corpus = tobows(train_by_type[document_type], dictionary_by_type[document_type])\n",
    "\n",
    "    lda = LDA.load(filename)\n",
    "    cm = CoherenceModel(\n",
    "        model=lda,\n",
    "        corpus=corpus,\n",
    "        dictionary=dictionary_by_type[document_type],\n",
    "        coherence='u_mass'\n",
    "    )\n",
    "\n",
    "    cm.save(filename.replace('lda', 'cm'))\n",
    "    print('*', end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict_train_test.pkl', 'rb') as fd:\n",
    "    dictionary_by_type, train_by_type, test_by_type = pickle.load(fd)\n",
    "\n",
    "acc = []\n",
    "for filename in glob(str(out / 'wide-*.lda')):\n",
    "    iterations, num_topics, document_type = get_i_t(filename)\n",
    "    train_corpus = tobows(train_by_type[document_type], dictionary_by_type[document_type])\n",
    "    test_corpus = tobows(test_by_type[document_type], dictionary_by_type[document_type])\n",
    "\n",
    "    lda = LDA.load(filename)\n",
    "    cm = CoherenceModel.load(filename.replace('lda', 'cm'))\n",
    "\n",
    "    try:\n",
    "        c = cm.get_coherence()\n",
    "    except:\n",
    "        c = float('nan')\n",
    "    row = [num_topics, iterations,\n",
    "           lda.log_perplexity(train_corpus), lda.log_perplexity(test_corpus),\n",
    "           c, document_type]\n",
    "\n",
    "    acc.append(row)    \n",
    "    print('*', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdiagnosis = DataFrame(\n",
    "    acc,\n",
    "    columns=['num_topics', 'iterations', \n",
    "             'train_perplexity', 'test_perplexity', \n",
    "             'coherence', 'document_type']\n",
    ").sort_values(['train_perplexity'], ascending=False)\n",
    "\n",
    "for document_type in wdiagnosis.document_type.unique():\n",
    "    display(document_type, \n",
    "            wdiagnosis[wdiagnosis.document_type==document_type].head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise \"pause\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict_train_test.pkl', 'rb') as fd:\n",
    "    dictionary_by_type, train_by_type, test_by_type = pickle.load(fd)\n",
    "\n",
    "try_by_type = {\n",
    "    'ISA' : Candidate(iterations=range(50, 275, 25), num_topics=range(35, 70, 5)),\n",
    "    'DPFR' : Candidate(iterations=range(100, 325, 25), num_topics=range(15, 50, 5)),\n",
    "    'PFR' : Candidate(iterations=range(225, 375, 25), num_topics=range(35, 70, 5)),\n",
    "}\n",
    "    \n",
    "for document_type in documents_by_type:\n",
    "    corpus = tobows(train_by_type[document_type], dictionary_by_type[document_type])\n",
    "\n",
    "    for iterations in try_by_type[document_type].iterations:\n",
    "        print(document_type, f'{iterations:03}', end=' - ')\n",
    "        for num_topics in try_by_type[document_type].num_topics:\n",
    "\n",
    "            lda = LDA(corpus=corpus,\n",
    "                        num_topics=num_topics,\n",
    "                        iterations=iterations,\n",
    "                       )\n",
    "            print(num_topics, end=':')\n",
    "\n",
    "            savename = f'narrow-i{iterations:03}_t{num_topics:03}_d-{document_type}'\n",
    "            lda.save(str(out / f'{savename}.lda'))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict_train_test.pkl', 'rb') as fd:\n",
    "    dictionary_by_type, train_by_type, test_by_type = pickle.load(fd)\n",
    "\n",
    "for filename in glob(str(out / f'narrow-*.lda')):\n",
    "    iterations, num_topics, document_type = get_i_t(filename)\n",
    "\n",
    "    corpus = tobows(train_by_type[document_type], dictionary_by_type[document_type])\n",
    "\n",
    "    lda = LDA.load(filename)\n",
    "    cm = CoherenceModel(\n",
    "        model=lda,\n",
    "        corpus=corpus,\n",
    "        dictionary=dictionary_by_type[document_type],\n",
    "        coherence='u_mass'\n",
    "    )\n",
    "\n",
    "    cm.save(filename.replace('lda', 'cm'))\n",
    "    print('*', end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict_train_test.pkl', 'rb') as fd:\n",
    "    dictionary_by_type, train_by_type, test_by_type = pickle.load(fd)\n",
    "\n",
    "acc = []\n",
    "for filename in glob(str(out / f'narrow-*.lda')):\n",
    "    iterations, num_topics, document_type = get_i_t(filename)\n",
    "\n",
    "    corpus = tobows(train_by_type[document_type], dictionary_by_type[document_type])\n",
    "    holdout = tobows(test_by_type[document_type], dictionary_by_type[document_type])\n",
    "\n",
    "    lda = LDA.load(filename)\n",
    "    cm = CoherenceModel.load(filename.replace('lda', 'cm'))\n",
    "\n",
    "    try:\n",
    "        c = cm.get_coherence()\n",
    "    except:\n",
    "        c = float('nan')\n",
    "    row = [num_topics, iterations, \n",
    "           lda.log_perplexity(corpus), lda.log_perplexity(holdout), \n",
    "           c, document_type]\n",
    "\n",
    "    acc.append(row)\n",
    "    print('*', end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndiagnosis = DataFrame(\n",
    "    acc, \n",
    "    columns=['num_topics', 'iterations', 'train_perplexity', 'test_perplexity',\n",
    "             'coherence', 'document_type']\n",
    ").sort_values(['coherence'], ascending=True)\n",
    "\n",
    "for document_type in ndiagnosis.document_type.unique():\n",
    "    info = ndiagnosis[ndiagnosis.document_type==document_type]\n",
    "    display(\n",
    "        document_type, min(info.num_topics),max(info.num_topics),\n",
    "        info.head(n=10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise \"pause\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict_train_test.pkl', 'rb') as fd:\n",
    "    dictionary_by_type, train_by_type, test_by_type = pickle.load(fd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_by_type = {\n",
    "    'ISA' :Candidate(iterations=150,  num_topics=60),\n",
    "    'PFR' :Candidate(iterations=250,  num_topics=55),\n",
    "    'DPFR':Candidate(iterations=250, num_topics=45),\n",
    "}\n",
    "\n",
    "\n",
    "with open('election_by_type.pkl', 'wb') as fd:\n",
    "    pickle.dump(election_by_type, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise \"pause\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict_train_test.pkl', 'rb') as fd:\n",
    "    dictionary_by_type, train_by_type, test_by_type = pickle.load(fd)\n",
    "\n",
    "\n",
    "with open('election_by_type.pkl', 'rb') as fd:\n",
    "    election_by_type = pickle.load(fd)\n",
    "\n",
    "model_by_type = dict()\n",
    "\n",
    "for document_type in election_by_type:\n",
    "    c = election_by_type[document_type]\n",
    "    filename = f'narrow-i{c.iterations:03}_t{c.num_topics:03}_d-{document_type}'\n",
    "    model_by_type[document_type] = LDA.load(str(out / f'{filename}.lda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#documents_by_type['ISA'].sort_values('Project_Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import logistic\n",
    "\n",
    "\n",
    "document_type = 'ISA'\n",
    "\n",
    "tump = documents_by_type[document_type].sort_values('Project_Code')\n",
    "dump = dictionary_by_type[document_type]\n",
    "mump = model_by_type[document_type]\n",
    "\n",
    "for project, documents in tump.groupby('Project_Code'):\n",
    "    gs = documents[target]\n",
    "    bow = dump.doc2bow(gs.str.cat().split())\n",
    "    topics = sorted(mump.get_document_topics(bow), key=itemgetter(1), reverse=True)\n",
    "\n",
    "    if False:\n",
    "        print(\n",
    "            f'{project} : {gs.size} documents', \n",
    "            *topics,\n",
    "            sep='\\n . '\n",
    "        )\n",
    "    else:\n",
    "        num_contrib = len(topics)\n",
    "        topic_words = ((mump.show_topic(t), v) for t, v in topics)\n",
    "        words = []\n",
    "        for wvalues, tvalue in topic_words:\n",
    "            scored = map(lambda w_v: (w_v[0], w_v[1]*tvalue), wvalues)\n",
    "            words.extend(scored)\n",
    "\n",
    "        result = dict()\n",
    "        for g, targets in groupby(sorted(words, key=itemgetter(0)), itemgetter(0)):\n",
    "            result[g] = sum(map(itemgetter(1), targets))\n",
    "\n",
    "        ranked = sorted(result.items(), key=itemgetter(1), reverse=True)\n",
    "        print(\n",
    "            f'{project} : {gs.size} documents, {num_contrib} topics', \n",
    "            *(dump[int(key)] for key, value in ranked if value > .002),\n",
    "            sep='\\n . ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_by_type.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prepared_data = {\n",
    "    document_type: ldavis.gensim.prepare(\n",
    "        model_by_type[document_type],\n",
    "        corpus=tobows(documents_by_type[document_type], dictionary_by_type[document_type]),\n",
    "        dictionary=dictionary_by_type[document_type],\n",
    "    )\n",
    "    for document_type in election_by_type}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for report_type in election_by_type:\n",
    "    display(prepared_data[report_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
