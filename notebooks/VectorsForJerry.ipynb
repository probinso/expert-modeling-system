{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from glob import glob\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel as LDA\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pandas import DataFrame, read_csv, concat\n",
    "\n",
    "import pyLDAvis as ldavis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ldavis.enable_notebook()\n",
    "%matplotlib notebook\n",
    "%precision 4\n",
    "\n",
    "out = Path('../output/')\n",
    "\n",
    "Candidate = namedtuple('Candidate', ['iterations', 'num_topics'])\n",
    "\n",
    "def get_i_t(filename):\n",
    "    _, content, document_type = filename.split('-')\n",
    "    i, t, _ = content.split('_')\n",
    "    return int(i[1:]), int(t[1:]), document_type.split('.')[0]\n",
    "\n",
    "get_texts = lambda df: df[target].str.split()\n",
    "tobows = lambda df, d: get_texts(df).apply(d.doc2bow)\n",
    "\n",
    "report_types = 'ISA', 'PFR', 'DPFR'\n",
    "\n",
    "test_size = .2\n",
    "min_occurances = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_by_type = {\n",
    "    t: read_csv(out / f'norm_{t}.csv').dropna()\n",
    "    for t in report_types\n",
    "}\n",
    "\n",
    "target = 'GLOMUNSTEM'\n",
    "\n",
    "with open('election_by_type.pkl', 'rb') as fd:\n",
    "    election_by_type = pickle.load(fd)\n",
    "\n",
    "with open('dict_train_test.pkl', 'rb') as fd:\n",
    "    dictionary_by_type, train_by_type, test_by_type = pickle.load(fd)\n",
    "\n",
    "model_by_type = dict()\n",
    "for document_type in election_by_type:\n",
    "    c = election_by_type[document_type]\n",
    "    filename = f'narrow-i{c.iterations:03}_t{c.num_topics:03}_d-{document_type}'\n",
    "    model_by_type[document_type] = LDA.load(str(out / f'{filename}.lda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document_type in report_types:\n",
    "    with open(document_type + '_topics_vectors.csv', 'w') as fd:\n",
    "        tump = documents_by_type[document_type]\n",
    "        dump = dictionary_by_type[document_type]\n",
    "        mump = model_by_type[document_type]\n",
    "\n",
    "        for _, doc in tump.iterrows():\n",
    "            gs = doc[target]\n",
    "            bow = dump.doc2bow(gs.split())\n",
    "\n",
    "            topics = mump.get_document_topics(bow, minimum_probability=-1)\n",
    "            print(doc['Anomaly_ID'], *map(itemgetter(1), topics), sep=',', file=fd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
