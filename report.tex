\documentclass{article}

\usepackage[affil-it]{authblk}

\usepackage[USenglish,american]{babel}
\usepackage[pdftex]{graphicx}
\usepackage{epstopdf}

\usepackage{cite}

\usepackage{amsfonts,amsmath,amsthm,amssymb}

\usepackage{tikz,pgf}
\usetikzlibrary{fit}

\usepackage{csvsimple}

%\pagestyle{empty}
\setlength{\parindent}{0mm}
\usepackage[letterpaper, margin=1in]{geometry}
%\usepackage{showframe}

\usepackage{multicol}
\usepackage{enumerate}

\usepackage{verbatim}
\usepackage{listings}

\usepackage{color}

%%
%% Julia definition (c) 2014 Jubobs
%%
\lstdefinelanguage{Julia}%
  {morekeywords={abstract,break,case,catch,const,continue,do,else,elseif,%
      end,export,false,for,function,immutable,import,importall,if,in,%
      macro,module,otherwise,quote,return,switch,true,try,type,typealias,%
      using,while},%
   sensitive=true,%
   alsoother={$},%
   morecomment=[l]\#,%
   morecomment=[n]{\#=}{=\#},%
   morestring=[s]{"}{"},%
   morestring=[m]{'}{'},%
}[keywords,comments,strings]%

\lstset{%
    language         = Python,
    basicstyle       = \footnotesize\ttfamily,,
    keywordstyle     = \bfseries\color{blue},
    stringstyle      = \color{magenta},
    commentstyle     = \color{red},
    showstringspaces = false,
    backgroundcolor  = \color{lightgray},
    numbers          = left,
    title            = \lstname,
    numberstyle      = \tiny\color{lightgray}\ttfamily,
}

\usepackage{xspace}
\usepackage{url}
\usepackage{cite}

\usepackage{titlesec}
\titlespacing*{\subsubsection}{0pt}{*0}{*0}
\titlespacing*{\subsection}{0pt}{0pt}{*0}
\titlespacing*{\section}{0pt}{0pt}{*0}

\newcommand{\Bold}{\mathbf}

\setlength{\parskip}{1em}
%\setlength{\parindent}{1em}

\title{SME retrieval by Author-Topic Modeling}
\date{\today}
\author{Philip Robinson}
\affil{NASA: Jet Propoultion Labratory}

\begin{document}

\maketitle

\begin{abstract}
  In a large community, enlisting potential collaborators and subject matter experts
  greatly impacts the success of a project. Inferring identification and ranking
  participants' relevant knowledge to a task or project is necessary to develop
  impactful teams from these large communities\cite{Minto2007}. This
  paper to provides an outlined and strategy to identify best participants from their
  document contributions to a corpus. Topic modeling, such as Biterm Topic Model (BTM)\cite{Yan2013,Chen2015}, Latent Dirichlet Allocation (LDA),
  and Correlated Topic Model (CTM), have long been used to group related topics\cite{Alghamdi2015}. Likewise,
  author modeling has been used to measure attribution\cite{Rexha2018} and
  contribution\cite{AldebeiHJ016}. Author-Topic modeling establishes strategy to
  relate topics to authors\cite{Rosen-Zvi2004}. Under the assumption that
  authorship implies relevant knowledge to a document's topic; explore
  the space of Author-Topic modeling as a mechanism for measuring expertise against a
  project description.
\end{abstract}

% http://www.sfp.caltech.edu/students/proposal/other_project_plans
% https://trs.jpl.nasa.gov/

\begin{multicols}{2}

\section{Introduction}

For my JPL fellowship I will be exploring Subject Matter Expert (SME) retrieval
from a collection of documents with attribution. SME retrieval is necessary for
building effective teams for specific projects. In order to best support the scale of an
institution like JPL/NASA, and domain specific nature of the problems they address, we are
interested in strategies to infer and retrieve SMEs. An effective SME retrieval program
significantly reduces coordination overhead of election and discovery of
contributors to complex, domain specific, problems.

JPL's \texttt{A-Team} explored, then developed, a now existing SME retrieval program.
In developing this program, teams cited work on hierarchical clustering by
frequent-itemsets\cite{wang2003,kiran2010}. Frequent-itemsets\cite{Agrawal1993} are a
relation mining tool, which have historically been used to discover hidden
subpopulations with a shared characteristic pool. From these document clusters, teams
developed an explorable authorship network. Clustering by frequent-itemsets has
supports relatively small document sizes, and of varying shape.

Unlike topic modeling, author-topic models attempt to describe the authors as
associated with topics. Since we are looking for SMEs,
author-modeling is a closer fit. The phrase ``author modeling'' has also been used
in techniques which are more concerned with literal text-content document
contribution and attribution\cite{Rexha2018}; we are not interested in these techniques.

\section{Objectives}

The goal of this project is to propose an alternative, or collaborative, strategy for
SME retrieval. The document set will be different from \texttt{A-Team}'s, although
not distinct. We will be working with Pre-Launch Failures (PFR)s and
Incident Surprise Anomalies (ISA)s from the Problem Reporting System
(PRS), but should be able to grow to more document types. This should also
serve as a bases for clustering document resources and document similarity metrics,
because the second project I've been tasked with is identifying multiple reports covering
the same topic.

In addition to developing clustering and retrieval strategy, this project should yield
a full, usable, search prototype. I discussed, with my mentors, the expectation of a
RESTful API to support this SME retrieval system.

\section{Approach}

I am interested using author-topic\cite{Rosen-Zvi2004} modeling (ATM) for
SME retrieval. The base algorithm for ATM is an
extension of LDA to model authors relation to topics as well. I will develop
a query system to rank Author-topics against project
descriptions and like documents.

There exists an open-source implementation of ATM in the \texttt{gensim}\cite{rehurek_lrec}
module for \texttt{python}. If this proves effective, I would like to explore
derivatives to ATM that rely on CTM instead of LDA. Unlike LDA, CTM models
relationships between topics as well. Although this strategy may have unforeseen time
cost in implementation. To my knowledge Author-Correlated-Topic Models (ACTM) are
not yet implemented.

Additionally, there exists an extension of CTM that respect document fields, called
Multi-field Correlated Field Topic Modeling\cite{Salomatin2009MultifieldCT}. If ACTM
proves more effective at author modeling then ATM, I would interpret this as a strong
indicator that AMFCTM would as well. Ideally, with a few more iterations, this
project could end in an impressively unmanageable acronym.

\section{Dragons}

Although the path through this proposal is fairly direct, some technical difficulties may arise.
The major difference between LDA and CTM, for instance, is the distribution used for modeling
documents. Although I do have some basic understanding of the tooling for Bayesian modeling,
I have not yet applied them to real problems, and do not know the computational or development
overhead associated with modifying these tools. I suspect that re-exploring probabilistic
programming languages with applications in mind will be fruitful in this effort.
I will be bringing some resources\cite{lambert2018} to aid this knowledge gap.

Other than MFCTM\cite{Salomatin2009MultifieldCT}, none of these topic models
address separate fields. More troubling, I haven't yet found good resources for
incorporating categorical or single value fields. The majority of approaches I've surveyed
treat documents as contiguous, which may not best model PRS documents.

Finally, not all of these models work well on all size documents. An investigation will
be needed to find the best model for the job. It is possible that, due to small document
sizes, a best implementation would be Author-Topic modeling over BTM.

\section{Evaluation}

The original ATM paper identifies a subset of the test documents to be of single author.
As long as these authors are appropriately represented in the training set, they act as
a strong litmus test against this author modeling technique. They also state and describe
the process for using these single author papers for perplexity.
\begin{quote}
  Perplexity is the standard measure for estimating the performance of a probabilistic model.
\end{quote}

It will be important that we investigate the stability of the models\cite{Yang2016}, in order
to incorporate later documents, while minimizing effect to the user experience.

In order to prevent over-fitting, we will need to have training and test SME sets.
I propose a test and training set split by bisecting by min-cut\cite{Feige2002} a graph where
authors are vertices, and edges exist for each co-authors relationship, and is labeled by
document name.

\section{Schedule}

\begin{enumerate}[\texttt{WK} 1 -]
  \setcounter{enumi}{-1}
\item Setup
  \begin{itemize}
  \item Gain access to data
  \item appraise proposal
  \item document target UX for final project
  \item read and explore examples from data set
  \item draft or adopt normalization strategy
  \item divide into toy, train, and test sets
  \item discuss/establish evaluation strategies
  \end{itemize}
\item Explore common clustering
  \begin{itemize}
  \item without authors
  \item with and without fields
  \end{itemize}
\item Explore clustering with author modeling, and compare improvements
\item Extend some topic-models with author-topic-modeling
\item (3 - continued)
\item (3 - continued), Data Store, RESTful API
\item (5 - continued), UI
\item Evaluation, performance, and stability metric
\item User testing, asses incorporating new documents
\item Reporting
\end{enumerate}

\section{Comments}

I recognize that this proposal may change dramatically with mentor input.
These strategies don't take into account any network representation of the authors,
which is distinct from the current implementation.
I am very interested to learn and explore more extensions, especially hierarchical
topic modeling, and topic-aware influence propagation. I suspect that these
extensions are closer to what \texttt{A-Team} has already developed.


\begin{comment}

%\subsection{What is general technical area in which you will be working?}
%\subsection{What is the problem that you are trying to solve?}
%\subsection{How did this problem arise?}
%\subsection{Why is this problem interesting or worthwhile?}
%\subsection{What is the status of related research by your mentor or group by the group that you will be joining?}
%\subsection{What will be the contribution and significance of your effort?}

\section{Objectives}


\section{Materials}
\section{Results}
\section{Discussion}
\subsection{Study Assumptions}
\subsection{Data Acquisition}
\end{comment}

\bibliography{references.bib}{}
\bibliographystyle{plain}
\end{multicols}

\end{document}
