@inproceedings{Rosen-Zvi2004,
 author = {Rosen-Zvi, Michal and Griffiths, Thomas and Steyvers, Mark and Smyth, Padhraic},
 title = {The Author-topic Model for Authors and Documents},
 booktitle = {Proceedings of the 20th Conference on Uncertainty in Artificial Intelligence},
 series = {UAI '04},
 year = {2004},
 isbn = {0-9749039-0-6},
 location = {Banff, Canada},
 pages = {487--494},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=1036843.1036902},
 acmid = {1036902},
 publisher = {AUAI Press},
 address = {Arlington, Virginia, United States},
}
@incollection{NIPS2005_2906,
title = {Correlated Topic Models},
author = {John D. Lafferty and David M. Blei},
booktitle = {Advances in Neural Information Processing Systems 18},
editor = {Y. Weiss and B. Sch\"{o}lkopf and J. C. Platt},
pages = {147--154},
year = {2006},
publisher = {MIT Press},
url = {http://papers.nips.cc/paper/2906-correlated-topic-models.pdf}
}
@article{Alghamdi2015,
year = {2015},
author = {Rubayyi Alghamdi and Khalid Alfalqi},
title = {A Survey of Topic Modeling in Text Mining},
journal = {International Journal of Advanced Computer Science and Applications},
doi = {10.14569/IJACSA.2015.060121},
url = {http://dx.doi.org/10.14569/IJACSA.2015.060121},
publisher = {The Science and Information Organization},
volume = {6},
number = {1},
}
@inbook{Salomatin2009MultifieldCT,
author = {Konstantin Salomatin and Yiming Yang and Abhimanyu Lad},
title = {Multi-field Correlated Topic Modeling},
booktitle = {Proceedings of the 2009 SIAM International Conference on Data Mining},
chapter = {},
pages = {628-637},
doi = {10.1137/1.9781611972795.54},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611972795.54},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611972795.54}
}
@Article{Rexha2018,
author="Rexha, Andi
and Kr{\"o}ll, Mark
and Ziak, Hermann
and Kern, Roman",
title="Authorship identification of documents with high content similarity",
journal="Scientometrics",
year="2018",
month="Apr",
day="01",
volume="115",
number="1",
pages="223--237",
abstract="The goal of our work is inspired by the task of associating segments of text to their real authors. In this work, we focus on analyzing the way humans judge different writing styles. This analysis can help to better understand this process and to thus simulate/ mimic such behavior accordingly. Unlike the majority of the work done in this field (i.e. authorship attribution, plagiarism detection, etc.) which uses content features, we focus only on the stylometric, i.e. content-agnostic, characteristics of authors. Therefore, we conducted two pilot studies to determine, if humans can identify authorship among documents with high content similarity. The first was a quantitative experiment involving crowd-sourcing, while the second was a qualitative one executed by the authors of this paper. Both studies confirmed that this task is quite challenging. To gain a better understanding of how humans tackle such a problem, we conducted an exploratory data analysis on the results of the studies. In the first experiment, we compared the decisions against content features and stylometric features. While in the second, the evaluators described the process and the features on which their judgment was based. The findings of our detailed analysis could (1) help to improve algorithms such as automatic authorship attribution as well as plagiarism detection, (2) assist forensic experts or linguists to create profiles of writers, (3) support intelligence applications to analyze aggressive and threatening messages and (4) help editor conformity by adhering to, for instance, journal specific writing style.",
issn="1588-2861",
doi="10.1007/s11192-018-2661-6",
url="https://doi.org/10.1007/s11192-018-2661-6"
}
@inproceedings{Minto2007,
 author = {Minto, Shawn and Murphy, Gail C.},
 title = {Recommending Emergent Teams},
 booktitle = {Proceedings of the Fourth International Workshop on Mining Software Repositories},
 series = {MSR '07},
 year = {2007},
 isbn = {0-7695-2950-X},
 pages = {5--},
 url = {https://doi.org/10.1109/MSR.2007.27},
 doi = {10.1109/MSR.2007.27},
 acmid = {1269021},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
}
@inproceedings{Yan2013,
 author = {Yan, Xiaohui and Guo, Jiafeng and Lan, Yanyan and Cheng, Xueqi},
 title = {A Biterm Topic Model for Short Texts},
 booktitle = {Proceedings of the 22Nd International Conference on World Wide Web},
 series = {WWW '13},
 year = {2013},
 isbn = {978-1-4503-2035-1},
 location = {Rio de Janeiro, Brazil},
 pages = {1445--1456},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2488388.2488514},
 doi = {10.1145/2488388.2488514},
 acmid = {2488514},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {biterm, content analysis, short text, topic model},
}
@inproceedings{AldebeiHJ016,
  author    = {Khaled Aldebei and
               Xiangjian He and
               Wenjing Jia and
               Jie Yang},
  title     = {Unsupervised Multi-Author Document Decomposition Based on Hidden Markov
               Model},
  booktitle = {Proceedings of the 54th Annual Meeting of the Association for Computational
               Linguistics, {ACL} 2016, August 7-12, 2016, Berlin, Germany, Volume
               1: Long Papers},
  year      = {2016},
  url       = {http://aclweb.org/anthology/P/P16/P16-1067.pdf},
  timestamp = {Mon, 15 Aug 2016 15:53:28 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/acl/AldebeiHJ016},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@InProceedings{kiran2010,
author="G.V.R., Kiran
and Shankar, Ravi
and Pudi, Vikram",
editor="Setchi, Rossitza
and Jordanov, Ivan
and Howlett, Robert J.
and Jain, Lakhmi C.",
title="Frequent Itemset Based Hierarchical Document Clustering Using Wikipedia as External Knowledge",
booktitle="Knowledge-Based and Intelligent Information and Engineering Systems",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="11--20",
abstract="High dimensionality is a major challenge in document clustering. Some of the recent algorithms address this problem by using frequent itemsets for clustering. But, most of these algorithms neglect the semantic relationship between the words. On the other hand there are algorithms that take care of the semantic relations between the words by making use of external knowledge contained in WordNet, Mesh, Wikipedia, etc but do not handle the high dimensionality. In this paper we present an efficient solution that addresses both these problems. We propose a hierarchical clustering algorithm using closed frequent itemsets that use Wikipedia as an external knowledge to enhance the document representation. We evaluate our methods based on F-Score on standard datasets and show our results to be better than existing approaches.",
isbn="978-3-642-15390-7"
}
@article{wang2003,
author = {C. M, Benjamin and Ke, Fung and Martin Ester, Wang},
year = {2003},
month = {04},
pages = {},
title = {Hierarchical Document Clustering Using Frequent Itemsets}
}
@article{Agrawal1993,
author = {Agrawal, Rakesh and Imielinski, T and Swami, Arun},
year = {1993},
month = {01},
pages = {},
title = {Mining Associations Between Sets of Items in Massive Databases},
booktitle = {Proceedings of the ACM-SIGMOD 1993 International Conference on Management of Data, 1993}
}
@inproceedings{rehurek_lrec,
title = {{Software Framework for Topic Modelling with Large Corpora}},
author = {Radim {\v R}eh{\r u}{\v r}ek and Petr Sojka},
booktitle = {{Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks}},
pages = {45--50},
year = 2010,
month = May,
day = 22,
publisher = {ELRA},
address = {Valletta, Malta},
note={\url{http://is.muni.cz/publication/884893/en}},
language={English}
}
@article{Feige2002,
author = {Feige, Uriel and Krauthgamer, Robert},
title = {A Polylogarithmic Approximation of the Minimum Bisection},
journal = {SIAM J. Comput.},
issue_date = {2002},
volume = {31},
number = {4},
month = apr,
year = {2002},
issn = {0097-5397},
pages = {1090--1118},
numpages = {29},
url = {http://dx.doi.org/10.1137/S0097539701387660},
doi = {10.1137/S0097539701387660},
acmid = {586910},
publisher = {Society for Industrial and Applied Mathematics},
address = {Philadelphia, PA, USA},
keywords = {approximation algorithms, divide and conquer, dynamic programming, graph partitioning, graph separators},
}
@article{TACL582,
        author = {Nguyen, Dat Quoc  and Billingsley, Richard  and Du, Lan  and Johnson, Mark },
        title = {Improving Topic Models with Latent Feature Word Representations},
        journal = {Transactions of the Association for Computational Linguistics},
        volume = {3},
        year = {2015},
        keywords = {},
        abstract = {Probabilistic topic models are widely used to discover latent topics in document collections, while latent feature vector representations of words have been used to obtain high performance in many NLP tasks. In this paper, we extend two different Dirichlet multinomial topic models by incorporating latent feature vector representations of words trained on very large corpora to improve the word-topic mapping learnt on a smaller corpus. Experimental results show that by using information from the external corpora, our new models produce significant improvements on topic coherence, document clustering and document classification tasks, especially on datasets with few or short documents.},
        issn = {2307-387X},
        url = {https://transacl.org/ojs/index.php/tacl/article/view/582},
        pages = {299--313}
}
@inproceedings{Chen2015,
  title={User Based Aggregation for Biterm Topic Model},
  author={Weizheng Chen and Jinpeng Wang and Yan Zhang and Hongfei Yan and Xiaoming Li},
  booktitle={ACL},
  year={2015}
}
@article{LimCB16,
  author    = {Kar Wai Lim and
               Changyou Chen and
               Wray L. Buntine},
  title     = {Twitter-Network Topic Model: {A} Full Bayesian Treatment for Social
               Network and Text Modeling},
  journal   = {CoRR},
  volume    = {abs/1609.06791},
  year      = {2016},
  url       = {http://arxiv.org/abs/1609.06791},
  archivePrefix = {arXiv},
  eprint    = {1609.06791},
  timestamp = {Wed, 07 Jun 2017 14:41:52 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/LimCB16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@book{lambert2018,
  title={A Student’s Guide to Bayesian Statistics},
  author={Lambert, B.},
  isbn={9781526418265},
  url={https://books.google.com/books?id=CLZBDwAAQBAJ},
  year={2018},
  publisher={SAGE Publications}
}
@unknown{Zhao2016,
author = {Zhao, Yukun and Liang, Shangsong and Ren, Zhaochun and Ma, Jun and Yilmaz, Emine and de Rijke, Maarten},
year = {2016},
month = {07},
pages = {155-164},
title = {Explainable User Clustering in Short Text Streams}
}
@article{doi:10.1093/llc/fqt066,
author = {Eder, Maciej},
title = {Does size matter? Authorship attribution, small samples, big problem},
journal = {Digital Scholarship in the Humanities},
volume = {30},
number = {2},
pages = {167-182},
year = {2015},
doi = {10.1093/llc/fqt066},
URL = {http://dx.doi.org/10.1093/llc/fqt066},
eprint = {/oup/backfile/content_public/journal/dsh/30/2/10.1093_llc_fqt066/4/fqt066.pdf},
abstract = {The aim of this study is to find such a minimal size of text samples for authorship attribution that would provide stable results independent of random noise. A few controlled tests for different sample lengths, languages, and genres are discussed and compared. Depending on the corpus used, the minimal sample length varied from 2,500 words (Latin prose) to 5,000 or so words (in most cases, including English, German, Polish, and Hungarian novels). Another observation is connected with the method of sampling: contrary to common sense, randomly excerpted ‘bags of words’ turned out to be much more effective than the classical solution, i.e. using original sequences of words (‘passages’) of desired size. Although the tests have been performed using the Delta method (Burrows, J.F. (2002). ‘Delta’: a measure of stylistic difference and a guide to likely authorship. Literary and Linguistic Computing, 17(3): 267–87) applied to the most frequent words, some additional experiments have been conducted for support vector machines and k-NN applied to most frequent words, character 3-grams, character 4-grams, and parts-of-speech-tag 3-grams. Despite significant differences in overall attributive success rate between particular methods and/or style markers, the minimal amount of textual data needed for reliable authorship attribution turned out to be method-independent.}
}
@article{Yang2016,
 author = {Yang, Yi and Pan, Shimei and Lu, Jie and Topkara, Mercan and Song, Yangqiu},
 title = {The Stability and Usability of Statistical Topic Models},
 journal = {ACM Trans. Interact. Intell. Syst.},
 issue_date = {August 2016},
 volume = {6},
 number = {2},
 month = jul,
 year = {2016},
 issn = {2160-6455},
 pages = {14:1--14:23},
 articleno = {14},
 numpages = {23},
 url = {http://doi.acm.org/10.1145/2954002},
 doi = {10.1145/2954002},
 acmid = {2954002},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {LDA, Statistical topic model, constrained topic model, non-disruptive topic model update, stability, text analytics, usability},
}
@article{Ren2013,
author = {Li Ren},
year = {2013},
title = {A Survey on Statistical Topic Modeling}
}
=======
>>>>>>> 4965869a8ec3c4b74c0b10d3cfa3722fc8cd8035
